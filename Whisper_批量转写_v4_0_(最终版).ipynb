{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx4neDLv0upyw1vlMj7y0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevin89887634/ChatGPT-wechat-bot/blob/master/Whisper_%E6%89%B9%E9%87%8F%E8%BD%AC%E5%86%99_v4_0_(%E6%9C%80%E7%BB%88%E7%89%88).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAFdsJlm8U0Q"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Whisper æ‰¹é‡è½¬å†™ v4.0 (æœ€ç»ˆç‰ˆ)\n",
        "\n",
        "æ ¸å¿ƒç‰¹æ€§ï¼š\n",
        "1.  ã€ä¸€ç«™å¼è·¯å¾„ã€‘ï¼šåªéœ€é…ç½®ä¸€ä¸ªé¡¹ç›®æ€»æ–‡ä»¶å¤¹ï¼Œè¾“å…¥è¾“å‡ºè·¯å¾„å…¨è‡ªåŠ¨ç®¡ç†ã€‚\n",
        "2.  ã€æ™ºèƒ½ä¾èµ–å®‰è£…ã€‘ï¼šè‡ªåŠ¨æ£€æŸ¥å¹¶å®‰è£…æ‰€éœ€åº“ï¼Œå®ç°å¼€ç®±å³ç”¨ã€‚\n",
        "3.  ã€ä¼ä¸šçº§å¥å£®æ€§ã€‘ï¼šåŒ…å«æ–­ç‚¹ç»­ä¼ ã€é”™è¯¯é‡è¯•ã€æ–‡ä»¶éªŒè¯å’Œè¯¦ç»†æ—¥å¿—ã€‚\n",
        "4.  ã€GPTæ–‡æœ¬æ ¡å¯¹ã€‘ï¼šå¯é€‰çš„GPT-4æ–‡æœ¬æ¶¦è‰²åŠŸèƒ½ï¼Œæå‡è½¬å†™è´¨é‡ã€‚\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "import logging\n",
        "from typing import Dict, Any, Tuple\n",
        "\n",
        "# ==============================================================================\n",
        "# 1.ã€ æ‚¨å”¯ä¸€éœ€è¦é…ç½®çš„åœ°æ–¹ ã€‘\n",
        "# ==============================================================================\n",
        "\n",
        "# è®¾ç½®æ‚¨åœ¨ Google Drive ä¸­çš„æ€»é¡¹ç›®æ–‡ä»¶å¤¹è·¯å¾„ã€‚\n",
        "# è„šæœ¬å°†è‡ªåŠ¨åœ¨æ­¤æ–‡ä»¶å¤¹å†…å¯»æ‰¾ \"_source_audios\" å­æ–‡ä»¶å¤¹ä½œä¸ºè¾“å…¥ï¼Œ\n",
        "# å¹¶è‡ªåŠ¨åˆ›å»º \"srt\", \"txt_corrected\" ç­‰æ–‡ä»¶å¤¹ç”¨äºå­˜æ”¾è¾“å‡ºã€‚\n",
        "PROJECT_FOLDER = \"/content/drive/MyDrive/MyWhisperProject\"\n",
        "\n",
        "# --- å¯é€‰é…ç½® ---\n",
        "\n",
        "# æ¨¡å‹é€‰æ‹©: \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n",
        "MODEL_SIZE = \"medium\"\n",
        "\n",
        "# æ˜¯å¦å¯ç”¨ GPT æ ¡å¯¹ï¼ˆéœ€è¦é…ç½®å¥½ API Keyï¼‰\n",
        "ENABLE_GPT_CORRECTION = True\n",
        "\n",
        "# ä¸´æ—¶æ€§é”™è¯¯ï¼ˆå¦‚ç½‘ç»œé—®é¢˜ï¼‰çš„é‡è¯•æ¬¡æ•°\n",
        "RETRY_COUNT = 3\n",
        "\n",
        "# ==============================================================================\n",
        "# 2.ã€ åŠ¨æ€è·¯å¾„ç”Ÿæˆ (æ— éœ€ä¿®æ”¹) ã€‘\n",
        "# ==============================================================================\n",
        "\n",
        "SOURCE_SUBFOLDER = \"_source_audios\"  # å­˜æ”¾æºæ–‡ä»¶çš„å­æ–‡ä»¶å¤¹åç§°\n",
        "\n",
        "# æ ¹æ®å”¯ä¸€çš„é¡¹ç›®æ–‡ä»¶å¤¹ï¼Œè‡ªåŠ¨ç”Ÿæˆæ‰€æœ‰å…¶ä»–è·¯å¾„\n",
        "INPUT_FOLDER = os.path.join(PROJECT_FOLDER, SOURCE_SUBFOLDER)\n",
        "OUTPUT_SRT = os.path.join(PROJECT_FOLDER, \"srt\")\n",
        "OUTPUT_TXT = os.path.join(PROJECT_FOLDER, \"txt_corrected\")\n",
        "OUTPUT_JSON = os.path.join(PROJECT_FOLDER, \"json\")\n",
        "LOG_FOLDER = os.path.join(PROJECT_FOLDER, \"logs\")\n",
        "PROGRESS_FILE = os.path.join(LOG_FOLDER, \"progress.json\")\n",
        "SESSION_LOG_FILE = os.path.join(LOG_FOLDER, f\"session_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3.ã€ åˆå§‹åŒ–ä¸ç¯å¢ƒè®¾ç½® (å…¨è‡ªåŠ¨) ã€‘\n",
        "# ==============================================================================\n",
        "\n",
        "# å…¨å±€æ—¥å¿—å™¨\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def auto_install_dependencies():\n",
        "    \"\"\"\n",
        "    æ™ºèƒ½æ£€æŸ¥å¹¶è‡ªåŠ¨å®‰è£…æ‰€æœ‰å¿…éœ€çš„ä¾èµ–åº“å’Œå·¥å…·ã€‚\n",
        "    \"\"\"\n",
        "    print(\"ğŸ“‹ æ­£åœ¨æ£€æŸ¥ç¯å¢ƒä¸ä¾èµ–åº“...\")\n",
        "\n",
        "    # æ£€æŸ¥ Python åº“ (whisper, openai)\n",
        "    required_libs = {\"whisper\": \"openai-whisper\", \"openai\": \"openai\"}\n",
        "    for lib_name, install_name in required_libs.items():\n",
        "        try:\n",
        "            importlib.import_module(lib_name)\n",
        "            print(f\"  âœ… ä¾èµ–åº“ '{lib_name}' å·²å®‰è£…ã€‚\")\n",
        "        except ImportError:\n",
        "            print(f\"  âš ï¸ ä¾èµ–åº“ '{lib_name}' æœªæ‰¾åˆ°ï¼Œæ­£åœ¨è‡ªåŠ¨å®‰è£…...\")\n",
        "            try:\n",
        "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", install_name])\n",
        "                print(f\"  âœ… æˆåŠŸå®‰è£… '{install_name}'ã€‚\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"  âŒ å®‰è£… '{install_name}' å¤±è´¥: {e}\")\n",
        "                print(\"  è¯·å°è¯•æ‰‹åŠ¨è¿è¡Œ 'pip install -U openai-whisper openai' åå†è¯•ã€‚\")\n",
        "                raise\n",
        "\n",
        "    # æ£€æŸ¥ç³»ç»Ÿå·¥å…· (ffmpeg/ffprobe)ï¼Œä¸»è¦é’ˆå¯¹ Colab ç¯å¢ƒ\n",
        "    try:\n",
        "        result = subprocess.run(['ffprobe', '-version'], capture_output=True, text=True, check=True)\n",
        "        print(\"  âœ… å·¥å…· 'ffmpeg' å·²å®‰è£…ã€‚\")\n",
        "    except (FileNotFoundError, subprocess.CalledProcessError):\n",
        "        print(\"  âš ï¸ å·¥å…· 'ffmpeg' æœªæ‰¾åˆ°ï¼Œæ­£åœ¨è‡ªåŠ¨å®‰è£… (éœ€è¦ sudo æƒé™)...\")\n",
        "        try:\n",
        "            # ä½¿ç”¨ apt-get å®‰è£…ï¼Œé€‚ç”¨äº Debian/Ubuntu/Colab\n",
        "            subprocess.check_call(['apt-get', 'install', '-y', 'ffmpeg'])\n",
        "            print(\"  âœ… æˆåŠŸå®‰è£… 'ffmpeg'ã€‚\")\n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ è‡ªåŠ¨å®‰è£… 'ffmpeg' å¤±è´¥: {e}\")\n",
        "            print(\"  å¦‚æœä¸åœ¨ Colab ç¯å¢ƒï¼Œè¯·æ ¹æ®æ‚¨çš„æ“ä½œç³»ç»Ÿæ‰‹åŠ¨å®‰è£… ffmpegã€‚\")\n",
        "            raise\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"è®¾ç½®æ—¥å¿—ã€æŒ‚è½½é©±åŠ¨å™¨å¹¶åˆ›å»ºç›®å½•ç»“æ„\"\"\"\n",
        "    # è®¾ç½®æ—¥å¿—\n",
        "    if not logger.hasHandlers():\n",
        "        os.makedirs(LOG_FOLDER, exist_ok=True)\n",
        "        logger.setLevel(logging.INFO)\n",
        "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "        # æ–‡ä»¶æ—¥å¿—\n",
        "        file_handler = logging.FileHandler(SESSION_LOG_FILE, encoding='utf-8')\n",
        "        file_handler.setFormatter(formatter)\n",
        "        logger.addHandler(file_handler)\n",
        "        # æ§åˆ¶å°æ—¥å¿—\n",
        "        stream_handler = logging.StreamHandler()\n",
        "        stream_handler.setFormatter(formatter)\n",
        "        logger.addHandler(stream_handler)\n",
        "\n",
        "    logger.info(\"æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆã€‚\")\n",
        "\n",
        "    # æŒ‚è½½ Google Drive å¹¶é…ç½® OpenAI API Key\n",
        "    try:\n",
        "        from google.colab import drive, userdata\n",
        "        if not os.path.ismount(\"/content/drive\"):\n",
        "            logger.info(\"ğŸ”— æ­£åœ¨æŒ‚è½½ Google Drive...\")\n",
        "            drive.mount(\"/content/drive\")\n",
        "        else:\n",
        "            logger.info(\"ğŸ”— Google Drive å·²æŒ‚è½½ã€‚\")\n",
        "\n",
        "        # åŠ¨æ€å¯¼å…¥ openai å¹¶è®¾ç½®key\n",
        "        if ENABLE_GPT_CORRECTION:\n",
        "            global openai\n",
        "            import openai\n",
        "            try:\n",
        "                openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "                if openai.api_key:\n",
        "                    logger.info(\"ğŸ”‘ æˆåŠŸåŠ è½½ OpenAI API Keyã€‚\")\n",
        "                else:\n",
        "                    logger.warning(\"âš ï¸ æœªåœ¨ Colab userdata ä¸­æ‰¾åˆ°'OPENAI_API_KEY'ï¼ŒGPT æ ¡å¯¹åŠŸèƒ½å°†ç¦ç”¨ã€‚\")\n",
        "            except Exception:\n",
        "                openai.api_key = None\n",
        "                logger.error(\"âš ï¸ åŠ è½½ OpenAI API Key å¤±è´¥ï¼ŒGPT æ ¡å¯¹åŠŸèƒ½å°†ç¦ç”¨ã€‚\")\n",
        "    except ImportError:\n",
        "        logger.warning(\"âš ï¸ æœªåœ¨ Google Colab ç¯å¢ƒä¸­è¿è¡Œï¼Œè·³è¿‡é©±åŠ¨å™¨æŒ‚è½½å’Œ userdata é…ç½®ã€‚\")\n",
        "        if ENABLE_GPT_CORRECTION:\n",
        "            # å°è¯•ä»ç¯å¢ƒå˜é‡åŠ è½½\n",
        "            import openai\n",
        "            openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
        "            if openai.api_key:\n",
        "                logger.info(\"ğŸ”‘ æˆåŠŸä»ç¯å¢ƒå˜é‡åŠ è½½ OpenAI API Keyã€‚\")\n",
        "            else:\n",
        "                logger.warning(\"âš ï¸ æœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ° OpenAI API Keyï¼ŒGPT æ ¡å¯¹åŠŸèƒ½å°†ç¦ç”¨ã€‚\")\n",
        "\n",
        "\n",
        "    # åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•\n",
        "    logger.info(\"ğŸ“ æ­£åœ¨åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„...\")\n",
        "    directories_to_create = [PROJECT_FOLDER, INPUT_FOLDER, OUTPUT_SRT, OUTPUT_TXT, OUTPUT_JSON, LOG_FOLDER]\n",
        "    for dir_path in directories_to_create:\n",
        "        try:\n",
        "            os.makedirs(dir_path, exist_ok=True)\n",
        "        except OSError as e:\n",
        "            logger.error(f\"åˆ›å»ºç›®å½•å¤±è´¥: {dir_path} - {e}\")\n",
        "            raise\n",
        "    logger.info(\"âœ… é¡¹ç›®ç›®å½•ç»“æ„å‡†å¤‡å°±ç»ªã€‚\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4.ã€ æ ¸å¿ƒåŠŸèƒ½æ¨¡å— (æ— éœ€ä¿®æ”¹) ã€‘\n",
        "# ==============================================================================\n",
        "\n",
        "# --- è¿›åº¦ç®¡ç† ---\n",
        "class ProgressManager:\n",
        "    \"\"\"ç®¡ç†å¤„ç†è¿›åº¦ï¼Œå®ç°æ–­ç‚¹ç»­ä¼ å’ŒçŠ¶æ€è®°å½•\"\"\"\n",
        "    def __init__(self, filepath: str):\n",
        "        self.filepath = filepath\n",
        "        self.data = self._load()\n",
        "\n",
        "    def _load(self) -> Dict[str, Any]:\n",
        "        if os.path.exists(self.filepath):\n",
        "            try:\n",
        "                with open(self.filepath, 'r', encoding='utf-8') as f:\n",
        "                    return json.load(f)\n",
        "            except (json.JSONDecodeError, IOError):\n",
        "                return {\"processed_files\": {}, \"failed_files\": {}}\n",
        "        return {\"processed_files\": {}, \"failed_files\": {}}\n",
        "\n",
        "    def save(self):\n",
        "        try:\n",
        "            with open(self.filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.data, f, ensure_ascii=False, indent=4)\n",
        "        except IOError as e:\n",
        "            logger.error(f\"æ— æ³•ä¿å­˜è¿›åº¦æ–‡ä»¶: {e}\")\n",
        "\n",
        "    def is_completed(self, file_hash: str, base_name: str) -> bool:\n",
        "        return file_hash in self.data.get(\"processed_files\", {}) and \\\n",
        "               all(os.path.exists(os.path.join(p, f\"{base_name}{ext}\")) for p, ext in\n",
        "                   [(OUTPUT_SRT, \".srt\"), (OUTPUT_TXT, \".txt\"), (OUTPUT_JSON, \".json\")])\n",
        "\n",
        "    def add_success(self, file_hash: str, file_path: str, info: Dict[str, Any]):\n",
        "        self.data.setdefault(\"processed_files\", {})[file_hash] = {\"file_path\": file_path, **info}\n",
        "        self.data.setdefault(\"failed_files\", {}).pop(file_hash, None)\n",
        "        self.save()\n",
        "\n",
        "    def add_failure(self, file_hash: str, file_path: str, reason: str):\n",
        "        self.data.setdefault(\"failed_files\", {})[file_hash] = {\"file_path\": file_path, \"reason\": reason, \"timestamp\": datetime.now().isoformat()}\n",
        "        self.save()\n",
        "\n",
        "    def get_summary(self) -> Tuple[int, int]:\n",
        "        return len(self.data.get(\"processed_files\", {})), len(self.data.get(\"failed_files\", {}))\n",
        "\n",
        "# --- æ–‡ä»¶å¤„ç† ---\n",
        "\n",
        "def get_file_hash(file_path: str) -> str:\n",
        "    \"\"\"è®¡ç®—æ–‡ä»¶çš„ MD5 å“ˆå¸Œå€¼\"\"\"\n",
        "    hash_md5 = hashlib.md5()\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()\n",
        "\n",
        "def validate_audio_file(file_path: str) -> Tuple[bool, Dict[str, Any]]:\n",
        "    \"\"\"éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€å¯è¯»ã€åŒ…å«éŸ³é¢‘æµä¸”æ—¶é•¿æœ‰æ•ˆ\"\"\"\n",
        "    if not os.path.exists(file_path): return False, {\"error\": \"æ–‡ä»¶ä¸å­˜åœ¨\"}\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"ffprobe\", \"-v\", \"quiet\", \"-print_format\", \"json\", \"-show_format\", \"-show_streams\", file_path],\n",
        "            capture_output=True, text=True, check=True\n",
        "        )\n",
        "        info = json.loads(result.stdout)\n",
        "        if not any(s.get(\"codec_type\") == \"audio\" for s in info.get(\"streams\", [])):\n",
        "            return False, {\"error\": \"æ–‡ä»¶ä¸åŒ…å«éŸ³é¢‘æµ\"}\n",
        "        duration = float(info.get(\"format\", {}).get(\"duration\", 0))\n",
        "        if duration < 0.1: return False, {\"error\": \"éŸ³é¢‘æ—¶é•¿è¿‡çŸ­\"}\n",
        "        return True, {\"duration\": duration}\n",
        "    except Exception:\n",
        "        return False, {\"error\": \"æ–‡ä»¶å·²æŸåæˆ–æ ¼å¼æ— æ³•è¯†åˆ«\"}\n",
        "\n",
        "def correct_text_with_gpt(text: str) -> str:\n",
        "    \"\"\"ä½¿ç”¨ GPT-3.5-turbo æ ¡å¯¹æ–‡æœ¬\"\"\"\n",
        "    if not ENABLE_GPT_CORRECTION or not hasattr(sys.modules[__name__], 'openai') or not openai.api_key:\n",
        "        return text\n",
        "\n",
        "    logger.info(\"  è°ƒç”¨ GPT è¿›è¡Œæ–‡æœ¬æ ¡å¯¹...\")\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æ–‡æœ¬æ ¡å¯¹ç¼–è¾‘ã€‚è¯·ä¿®æ­£ä»¥ä¸‹æ–‡æœ¬ä¸­çš„é”™åˆ«å­—ã€æ ‡ç‚¹å’Œè¯­æ³•é—®é¢˜ï¼Œä½¿å…¶æ›´æµç•…ã€å‡†ç¡®ï¼Œä½†å¿…é¡»ä¿æŒåŸæ„ã€‚ç›´æ¥è¿”å›ä¿®æ­£åçš„æ–‡æœ¬ã€‚\"},\n",
        "                {\"role\": \"user\", \"content\": text}\n",
        "            ],\n",
        "            temperature=0.2, max_tokens=4000\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"  GPT æ ¡å¯¹å¤±è´¥: {e}ã€‚å°†è¿”å›åŸå§‹æ–‡æœ¬ã€‚\")\n",
        "        raise IOError(\"GPT API call failed\") from e # æŠ›å‡ºå¯é‡è¯•çš„é”™è¯¯\n",
        "\n",
        "def process_single_file(file_path: str, model: Any, progress_manager: ProgressManager) -> str:\n",
        "    \"\"\"å¤„ç†å•ä¸ªæ–‡ä»¶çš„å®Œæ•´æµç¨‹\"\"\"\n",
        "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "    try:\n",
        "        file_hash = get_file_hash(file_path)\n",
        "    except FileNotFoundError:\n",
        "        return \"error_file_not_found\"\n",
        "\n",
        "    if progress_manager.is_completed(file_hash, base_name):\n",
        "        return \"skipped\"\n",
        "\n",
        "    is_valid, validation_info = validate_audio_file(file_path)\n",
        "    if not is_valid:\n",
        "        progress_manager.add_failure(file_hash, file_path, f\"æ–‡ä»¶éªŒè¯å¤±è´¥: {validation_info.get('error')}\")\n",
        "        return \"error_validation\"\n",
        "\n",
        "    try:\n",
        "        result = model.transcribe(file_path, verbose=False)\n",
        "        raw_text = \"\\n\".join([seg[\"text\"].strip() for seg in result[\"segments\"]])\n",
        "        corrected_text = correct_text_with_gpt(raw_text) if \"zh\" in result.get(\"language\", \"\") else raw_text\n",
        "\n",
        "        # ä¿å­˜æ‰€æœ‰è¾“å‡ºæ–‡ä»¶\n",
        "        with open(os.path.join(OUTPUT_SRT, base_name + \".srt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            for idx, seg in enumerate(result[\"segments\"]):\n",
        "                start_t = datetime.utcfromtimestamp(seg['start']).strftime('%H:%M:%S,%f')[:-3]\n",
        "                end_t = datetime.utcfromtimestamp(seg['end']).strftime('%H:%M:%S,%f')[:-3]\n",
        "                f.write(f\"{idx+1}\\n{start_t} --> {end_t}\\n{seg['text'].strip()}\\n\\n\")\n",
        "\n",
        "        with open(os.path.join(OUTPUT_TXT, base_name + \".txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(corrected_text)\n",
        "\n",
        "        result['corrected_text'] = corrected_text\n",
        "        with open(os.path.join(OUTPUT_JSON, base_name + \".json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(result, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "        progress_manager.add_success(file_hash, file_path, {\"language\": result.get(\"language\"), \"duration\": validation_info.get('duration'), \"timestamp\": datetime.now().isoformat()})\n",
        "        return \"success\"\n",
        "    except IOError as e: # GPT è°ƒç”¨å¤±è´¥\n",
        "        progress_manager.add_failure(file_hash, file_path, f\"å¯æ¢å¤é”™è¯¯: {e}\")\n",
        "        return \"error_retryable\"\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿä¸å¯æ¢å¤çš„ä¸¥é‡é”™è¯¯: {e}\", exc_info=True)\n",
        "        progress_manager.add_failure(file_hash, file_path, f\"ä¸¥é‡é”™è¯¯: {e}\")\n",
        "        return \"error_critical\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 5.ã€ ä¸»ç¨‹åºå…¥å£ ã€‘\n",
        "# ==============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"ä¸»å‡½æ•°ï¼Œè´Ÿè´£ç¼–æ’æ•´ä¸ªæ‰¹é‡å¤„ç†æµç¨‹ã€‚\"\"\"\n",
        "\n",
        "    # æ­¥éª¤ 1: æ™ºèƒ½å®‰è£…ä¾èµ–\n",
        "    try:\n",
        "        auto_install_dependencies()\n",
        "        import whisper # ç¡®ä¿ whisper åœ¨å®‰è£…åå¯ç”¨\n",
        "    except Exception:\n",
        "        print(\"âŒ ä¾èµ–å®‰è£…å¤±è´¥ï¼Œç¨‹åºæ— æ³•ç»§ç»­ã€‚è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚\")\n",
        "        return\n",
        "\n",
        "    # æ­¥éª¤ 2: åˆå§‹åŒ–ç¯å¢ƒ\n",
        "    setup_environment()\n",
        "    logger.info(\"ğŸš€ å¯åŠ¨ Whisper æ‰¹é‡è½¬å†™å¢å¼ºç‰ˆ v4.0\")\n",
        "    logger.info(f\"é¡¹ç›®æ–‡ä»¶å¤¹: {PROJECT_FOLDER}\")\n",
        "\n",
        "    # æ­¥éª¤ 3: æ–‡ä»¶æ‰«æ\n",
        "    logger.info(f\"ğŸ” æ­£åœ¨æ‰«æè¾“å…¥æ–‡ä»¶å¤¹: {INPUT_FOLDER}\")\n",
        "    VALID_EXT = [\".mp3\", \".mp4\", \".m4a\", \".wav\", \".webm\", \".aac\", \".mov\", \".wmv\", \".flac\", \".ogg\"]\n",
        "    all_files = [os.path.join(root, f) for root, _, files in os.walk(INPUT_FOLDER) for f in files if os.path.splitext(f)[1].lower() in VALID_EXT]\n",
        "\n",
        "    if not all_files:\n",
        "        logger.warning(f\"âš ï¸ åœ¨ '{INPUT_FOLDER}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„éŸ³è§†é¢‘æ–‡ä»¶ã€‚\")\n",
        "        logger.warning(\"è¯·ç¡®ä¿æ‚¨çš„éŸ³é¢‘æ–‡ä»¶å·²æ”¾å…¥æ­£ç¡®çš„å­æ–‡ä»¶å¤¹ä¸­ã€‚\")\n",
        "        return\n",
        "    logger.info(f\"ğŸ“¦ å‘ç° {len(all_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶ã€‚\")\n",
        "\n",
        "    # æ­¥éª¤ 4: åŠ è½½æ¨¡å‹å’Œè¿›åº¦ç®¡ç†å™¨\n",
        "    progress_manager = ProgressManager(PROGRESS_FILE)\n",
        "    logger.info(f\"â³ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹: {MODEL_SIZE} (æ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...\")\n",
        "    try:\n",
        "        model = whisper.load_model(MODEL_SIZE)\n",
        "        logger.info(\"âœ… Whisper æ¨¡å‹åŠ è½½å®Œæˆã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"âŒ åŠ è½½ Whisper æ¨¡å‹å¤±è´¥: {e}ã€‚ç¨‹åºå·²ç»ˆæ­¢ã€‚\")\n",
        "        return\n",
        "\n",
        "    # æ­¥éª¤ 5: æ‰¹é‡å¤„ç†\n",
        "    success_count, failed_count = progress_manager.get_summary()\n",
        "    with tqdm(total=len(all_files), desc=\"æ€»ä½“è¿›åº¦\", unit=\"ä¸ª\") as pbar:\n",
        "        pbar.update(success_count + failed_count)\n",
        "        for file_path in all_files:\n",
        "            filename = os.path.basename(file_path)\n",
        "            pbar.set_description(f\"å¤„ç†: {filename[:25]:<25}\")\n",
        "\n",
        "            for attempt in range(RETRY_COUNT + 1):\n",
        "                status = process_single_file(file_path, model, progress_manager)\n",
        "                if status != \"error_retryable\":\n",
        "                    break\n",
        "                logger.warning(f\"æ–‡ä»¶ {filename} å‡ºç°å¯æ¢å¤é”™è¯¯ (å°è¯• {attempt + 1}/{RETRY_COUNT})ï¼Œå°†åœ¨5ç§’åé‡è¯•...\")\n",
        "                time.sleep(5)\n",
        "\n",
        "            if status == \"success\" or status == \"skipped\":\n",
        "                pbar.update(1)\n",
        "            else: # å„ç§å¤±è´¥æƒ…å†µ\n",
        "                pbar.update(1) # å¤±è´¥ä¹Ÿç®—å¤„ç†äº†ä¸€ä¸ª\n",
        "\n",
        "            current_success, current_failed = progress_manager.get_summary()\n",
        "            pbar.set_postfix({\"æˆåŠŸ\": current_success, \"å¤±è´¥\": current_failed})\n",
        "\n",
        "    # æ­¥éª¤ 6: ç»“æŸæ±‡æ€»\n",
        "    logger.info(\"ğŸ‰ æ‰¹é‡å¤„ç†å…¨éƒ¨å®Œæˆï¼\")\n",
        "    final_success, final_failed = progress_manager.get_summary()\n",
        "    logger.info(f\"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: æˆåŠŸ {final_success} ä¸ª, å¤±è´¥ {final_failed} ä¸ªã€‚\")\n",
        "    if final_failed > 0:\n",
        "        logger.warning(\"--- ä»¥ä¸‹æ–‡ä»¶å¤„ç†å¤±è´¥ ---\")\n",
        "        for details in progress_manager.data.get('failed_files', {}).values():\n",
        "            logger.warning(f\"  - æ–‡ä»¶: {details['file_path']}\")\n",
        "            logger.warning(f\"    åŸå› : {details['reason']}\")\n",
        "        logger.warning(\"----------------------\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}